Excellent question! DVF (Desirability, Viability, Feasibility) is IDEO's design thinking framework and it fits beautifully as a **qualitative front-end filter** in the prioritization approach I outlined. Here's how it integrates:

## DVF as the First Layer in Multi-Framework Prioritization

DVF works best as your **strategic categorization layer** before applying quantitative scoring. In the three-layer approach I described, DVF would replace or complement MoSCoW at the initial screening stage:

**Layer 1: DVF Screening** (Qualitative)

- Filters out ideas that fail any dimension
- Creates initial categories based on the "sweet spot" intersection

**Layer 2: RICE/WSJF Scoring** (Quantitative)

- Applies numerical prioritization within viable ideas
- Sequences based on economic value

**Layer 3: Stakeholder Validation** (Consensus)

- Confirms through Priority Poker or other techniques

## Strong Alignment with BXT Framework

You'll notice DVF maps almost perfectly to Microsoft's BXT Framework I mentioned: Business (Viability), eXperience (Desirability), Technology (Feasibility). Both frameworks share the same philosophical foundation—successful initiatives must satisfy all three dimensions simultaneously.

## When DVF Excels in IT Programmes

DVF prevents costly failures by assessing all three dimensions early, aligns cross-functional teams by encouraging collaboration between design, engineering, and business, and improves user-centricity by forcing teams to validate desirability first. This makes it particularly valuable for:

**Innovation & Product Development**

- Early-stage validation when brainstorming—teams mostly start with desirability since if no one wants the product, the other two don't matter
- Digital transformation initiatives where user adoption is critical
- New service design or experience improvement programmes

**Cross-Functional Alignment**

- Engineers weigh in on feasibility, finance teams assess viability, and UX designers validate desirability
- Gets stakeholders speaking a common language before diving into numbers

**Filtering Large Idea Backlogs**

- Quickly eliminates ideas that fail any dimension (not feasible with current tech, not viable financially, or simply not desirable to users)
- Done right, a DVF framework acts as a set of traffic lights in the early stages of proposition development

## Practical Scoring Approaches

Tools like Prioritizr allow scoring issues in Jira across each DVF dimension, with the total DVF score ranging from 0 to 3. A more sophisticated approach involves:

1. **Weighted DVF**: Score each dimension (typically 1-5 scale), apply weights based on organizational priorities, calculate total scores, and regularly recalibrate as business environment changes
2. **Custom Parameters**: Set individual parameters or questions under each DVF section that contribute individual scores, carefully crafted for each project rather than adopting a 'shopping list' approach
3. **Traffic Light System**: Simple Red/Yellow/Green assessment for each dimension as initial filter, then detailed scoring for "all green" initiatives

## Evolution: DVFS (Adding Sustainability)

The methodology has evolved to DVFS, adding Sustainability as a fourth dimension—addressing resource usage, recyclability, and environmental impact. This reflects 2025's emphasis on ESG factors in IT programme governance and is particularly relevant for infrastructure and data center initiatives.

## DVF's Limitations in IT Programme Context

DVF oversimplifies complex decisions as real-world product development isn't always a clear-cut balance—external factors like regulation, competition, and market timing can disrupt the balance. It's not a standalone framework and doesn't provide execution details. Specifically for IT programmes:

- **No sequencing logic**: DVF tells you what's viable but not what to do first
- **No dependency handling**: Doesn't account for technical or resource dependencies
- **Limited economic optimization**: Unlike WSJF, doesn't optimize for flow or cost of delay
- **Subjective scoring**: Assessing DVF often relies on educated guesses—without key product metrics, teams risk making poor assumptions

## Recommended Integration Pattern

For IT programme managers, I'd recommend this flow:

1. **DVF Initial Filter** (Week 1)
   - Workshop format with cross-functional team
   - Assess all proposed use cases on 1-5 scale for each dimension
   - Eliminate any initiative scoring <3 on any dimension
   - Create "viable candidates" list
2. **Detailed Quantitative Scoring** (Week 2-3)
   - Apply WSJF for SAFe environments or RICE for product-focused work
   - Score only the DVF-approved candidates
   - Account for dependencies and technical constraints
3. **Portfolio Balancing** (Week 4)
   - Use Value-Effort Matrix to visualize distribution
   - Ensure mix of quick wins and strategic investments
   - Validate through stakeholder Priority Poker sessions
4. **Continuous Reassessment**
   - Regularly review and recalibrate as an idea that scored low on feasibility might become more feasible as your organization's capabilities grow

This hybrid approach leverages DVF's strength in early-stage, qualitative filtering while addressing its limitations through quantitative frameworks that optimize sequencing and economic value.